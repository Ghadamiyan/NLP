{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numbers\n",
    "from num2words import num2words\n",
    "import collections\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import nltk.collocations\n",
    "import nltk.corpus\n",
    "import collections\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tag.stanford import StanfordPOSTagger\n",
    "from nltk.corpus import senseval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances = senseval.instances('interest.pos')\n",
    "size = int(len(instances) * 0.1)\n",
    "train_set, test_set = instances[size:], instances[:size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SensevalInstance(word='interest-n', position=18, context=[('yields', 'NNS'), ('on', 'IN'), ('money-market', 'JJ'), ('mutual', 'JJ'), ('funds', 'NNS'), ('continued', 'VBD'), ('to', 'TO'), ('slide', 'VB'), (',', ','), ('amid', 'IN'), ('signs', 'VBZ'), ('that', 'IN'), ('portfolio', 'NN'), ('managers', 'NNS'), ('expect', 'VBP'), ('further', 'JJ'), ('declines', 'NNS'), ('in', 'IN'), ('interest', 'NN'), ('rates', 'NNS'), ('.', '.')], senses=('interest_6',))\n"
     ]
    }
   ],
   "source": [
    "print(instances[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numbers_(str_):\n",
    "    ch = []\n",
    "    for c in str_:\n",
    "        if c.isdigit():\n",
    "            ch.append(c)        \n",
    "    return int(''.join(map(str, ch))) \n",
    "\n",
    "def get_wordnet_pos(tag):\n",
    "\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = []\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "import string\n",
    "\n",
    "for instance in instances:\n",
    "    for tup in instance.context:\n",
    "        if tup[0] not in string.punctuation:\n",
    "            vocab.append(lemmatizer.lemmatize(tup[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for instance in instances:\n",
    "    for sense in instance.senses:\n",
    "        labels.append(numbers_(sense))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (int(0.9*len(instances)\n",
    "data = []\n",
    "\n",
    "for instance in instances:  \n",
    "    \n",
    "    words = ''\n",
    "    for word in instance.context:\n",
    "        words+=' '+str(lemmatizer.lemmatize(word[0]))\n",
    "               \n",
    "    bag_vector = np.zeros(len(vocab))        \n",
    "    for w in words:            \n",
    "        for j, word_ in enumerate(vocab):                \n",
    "            if word_ == w:                     \n",
    "                bag_vector[j] += 1   \n",
    "                \n",
    "    data.append(bag_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data test_data = data[:int(0.9*len(featuresets))], featuresets[int(0.9*len(featuresets)):]\n",
    "train_labels, test_labels = labels[:int(0.9*len(featuresets))], labelsint[(0.9*len(featuresets)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB  \n",
    "\n",
    "cls = MultinomialNB(alpha = 0.1)\n",
    "cls.fit(train_data, train_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
