{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\ACASA-\n",
      "[nltk_data]     PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\ACASA-\n",
      "[nltk_data]     PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\ACASA-\n",
      "[nltk_data]     PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numbers\n",
    "from num2words import num2words\n",
    "import collections\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import nltk.collocations\n",
    "import nltk.corpus\n",
    "import collections\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tag.stanford import StanfordPOSTagger\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(data):\n",
    "\n",
    "    from nltk.corpus import stopwords\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    translate_table = dict((ord(char), None) for char in string.punctuation) \n",
    "    data1 = data.translate(translate_table)\n",
    "    data2 = word_tokenize(data1)\n",
    "\n",
    "    data2 = [w.lower() for w in data2]\n",
    "\n",
    "    stopwords = set(stopwords.words('english'))\n",
    "    data3= [x for x in data2 if not x in stopwords]  \n",
    "\n",
    "    preprocessed_data  = []\n",
    "    for word in data3:\n",
    "        preprocessed_data.append(lemmatizer.lemmatize(word))\n",
    "\n",
    "    return preprocessed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_glosses(gloss1, gloss2):\n",
    "    \n",
    "    gloss_1 = preprocessing(gloss1)\n",
    "    gloss_2 = preprocessing(gloss2)\n",
    "\n",
    "    score = 0\n",
    "    for word1 in gloss_1:\n",
    "        for word2 in gloss_2:\n",
    "            if word1 == word2:\n",
    "                score += 1\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Original_Lesk(context, word, pos_tag):\n",
    "    \n",
    "    maximum_score = 0\n",
    "    result = None\n",
    "    \n",
    "    for word_sense in wordnet.synsets(word):\n",
    "        if word_sense.pos() == pos_tag:\n",
    "            sense_score = 0\n",
    "\n",
    "            for cont in context:    \n",
    "                for context_sense in wordnet.synsets(cont):\n",
    "                    if context_sense.pos() == pos_tag:\n",
    "                        sense_score += len(set(preprocessing(word_sense.definition())) & set(preprocessing(context_sense.definition())))\n",
    "\n",
    "            if sense_score > maximum_score:\n",
    "                maximum_score = sense_score\n",
    "                result = word_sense\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Synset('school.n.04')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Original_Lesk(nltk.word_tokenize('Students enjoy going to school, studying and reading books'), 'school', 'n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Synset('school.n.06')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.wsd import lesk\n",
    "lesk(nltk.word_tokenize('Students enjoy going to school, studying and reading books'),'school','n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(music) the sounds produced by singers or musical instruments (or reproductions of such sounds)'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syns=wordnet.synset('music.n.04')\n",
    "syns.definition()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extended Lesk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def glosses_of_synsets(synset):\n",
    "    \n",
    "\n",
    "    hypernyms = ''\n",
    "    for hypernym in synset.hypernyms():\n",
    "        hypernyms += hypernym.definition()\n",
    "        \n",
    "    hyponyms = ''\n",
    "    for hyponym in synset.hyponyms():\n",
    "        hyponyms += hyponym.definition()\n",
    "    \n",
    "    holonyms = ''\n",
    "    for holonym in synset.substance_holonyms() + synset.part_holonyms() + synset.part_holonyms():\n",
    "        holonyms += holonym.definition()\n",
    "    \n",
    "    meronyms = ''\n",
    "    for meronym in synset.substance_meronyms() + synset.part_meronyms() + synset.part_meronyms():\n",
    "        meronyms += meronym.definition()\n",
    "    \n",
    "    troponyms = ''\n",
    "    for troponym in synset.entailments():\n",
    "        troponyms += troponym.definition()\n",
    "    \n",
    "    attributes = ''\n",
    "    for attribute in synset.attributes():\n",
    "        attributes += attribute.definition()\n",
    "    \n",
    "    similars = ''\n",
    "    for similar in synset.similar_tos():\n",
    "        similars += similar.definition()\n",
    "    \n",
    "    alsos = ''\n",
    "    for also in synset.also_sees():\n",
    "        alsos += also.definition()\n",
    "\n",
    "    return [hypernyms,hyponyms,holonyms,meronyms,troponyms,attributes,similars,alsos]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a fluid in the gaseous state having neither independent shape nor volume and being able to expand indefinitely',\n",
       " 'the air that is inhaled and exhaled in respirationair that has been heated and tends to riseair in a liquid state',\n",
       " 'air moving (sometimes with considerable force) from an area of high pressure to an area of low pressure',\n",
       " \"a colorless and odorless inert gas; one of the six inert gases; comprises approximately 1% of the earth's atmospherea colorless element that is one of the six inert gasses; occurs in trace amounts in aira colorless odorless gaseous element that give a red glow in a vacuum tube; one of the six inert gasses; occurs in the air in small amountsa common nonmetallic element that is normally a colorless odorless tasteless inert diatomic gas; constitutes 78 percent of the atmosphere by volume; a constituent of all living tissuesa nonmetallic bivalent element that is normally a colorless odorless tasteless nonflammable diatomic gas; constitutes 21 percent of the atmosphere by volume; the most abundant element in the earth's crusta colorless odorless inert gaseous element occurring in the earth's atmosphere in trace amounts\",\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glosses_of_synsets(wordnet.synset('air.n.01'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
