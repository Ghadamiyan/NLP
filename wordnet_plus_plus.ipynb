{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numbers\n",
    "from num2words import num2words\n",
    "import collections\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import nltk.collocations\n",
    "import nltk.corpus\n",
    "import collections\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tag.stanford import StanfordPOSTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def getWikiSenses(word):\n",
    "    \n",
    "    #create a connection(session)\n",
    "    r_session = requests.Session()\n",
    "\n",
    "    #url for the MediaWiki action API\n",
    "    URL = \"https://en.wikipedia.org/w/api.php\"\n",
    "\n",
    "    PARAMS = {\n",
    "        \"action\": \"query\", #we are creating a query\n",
    "        \"titles\": word, #for the title input param    \n",
    "        \"prop\": \"redirects\", #asking for all the redirects (to the title car)\n",
    "        \"format\": \"json\" #and we want the output in a json format\n",
    "    }\n",
    "\n",
    "    #we obtain the response to the get request with the given parmeters\n",
    "    query_response = r_session.get(url=URL, params=PARAMS)\n",
    "    json_data = query_response.json()\n",
    "\n",
    "    #print(json_data)\n",
    "    wikipedia_pages = json_data[\"query\"][\"pages\"]\n",
    "\n",
    "    #we iterate through items and print all the redirects (their title and id)\n",
    "    try:\n",
    "        L = []\n",
    "        for k, v in wikipedia_pages.items():\n",
    "            for redir in v[\"redirects\"]:\n",
    "                if redir[\"title\"].isalpha():             \n",
    "                    L.append((redir[\"title\"], redir[\"pageid\"]))\n",
    "                \n",
    "        return L\n",
    "    except KeyError as err:\n",
    "        if err.args[0]=='redirects':\n",
    "            \n",
    "            return []\n",
    "        else:\n",
    "            print(repr(err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('tree.n.01'), Synset('tree.n.02'), Synset('tree.n.03'), Synset('corner.v.02'), Synset('tree.v.02'), Synset('tree.v.03'), Synset('tree.v.04')]\n"
     ]
    }
   ],
   "source": [
    "WordNet_senses = wordnet.synsets('tree')\n",
    "print(WordNet_senses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Trees', 546743), ('Sapling', 982234), ('Arboreus', 9996504), ('Macrophanerophyte', 23637495), ('Treee', 41412516)]\n"
     ]
    }
   ],
   "source": [
    "Wikipedia_senses = getWikiSenses('tree')\n",
    "print(Wikipedia_senses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_ = {}\n",
    "for w in Wikipedia_senses:\n",
    "    map_[w] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in Wikipedia_senses:\n",
    "    \n",
    "    wiki = getWikiSenses(w[1])\n",
    "    wn = wordnet.synsets(w[0])\n",
    "    \n",
    "    if len(wiki) == 1  and len(wn) == 1:\n",
    "        map_[w] = wn[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in Wikipedia_senses:\n",
    "    \n",
    "    if map_[w] is None:\n",
    "        wiki = getWikiSenses(w[1])\n",
    "        \n",
    "        for d in wiki:\n",
    "            if map_[d] is not None and map_[w] in wordnet.synsets(w[0]):\n",
    "                map_[w] = map_[d]\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('Trees', 546743): None, ('Sapling', 982234): None, ('Arboreus', 9996504): None, ('Macrophanerophyte', 23637495): None, ('Treee', 41412516): None}\n"
     ]
    }
   ],
   "source": [
    "print(map_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
